{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pyxdf\n",
    "import pickle\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_list =glob.glob('data/*/ses-S001/*/*.xdf')\n",
    "experiment_list = glob.glob('data/*/ses-S002/*/*.xdf')\n",
    "sfreq = 250\n",
    "info = mne.create_info(8, sfreq, [\"eeg\"] * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trails(current_experiment_list: list , baseline_list:list) -> dict:\n",
    "    baseline_mne_list = []\n",
    "    for baseline in baseline_list:\n",
    "        streams, _ = pyxdf.load_xdf(baseline,verbose=False)\n",
    "        try:\n",
    "            data = streams[1][\"time_series\"].T[:8]\n",
    "        except AttributeError:\n",
    "            data = streams[0][\"time_series\"].T[:8]\n",
    "        raw = mne.io.RawArray(data, info, verbose=False)\n",
    "        raw = raw.crop(tmin=1, tmax=41)\n",
    "        baseline_mne_list.append(raw)\n",
    "    trials = { \n",
    "            'ball': list(),\n",
    "            'ball+number': list(),\n",
    "            'ball+number+wheel': list(),\n",
    "            'baseline': baseline_mne_list,\n",
    "            }\n",
    "\n",
    "    for experiment in current_experiment_list:\n",
    "        print(\"processing: \", experiment)\n",
    "        streams, _ = pyxdf.load_xdf(experiment)\n",
    "        marker = -1 \n",
    "        eeg = -1\n",
    "        for idx, stream in enumerate(streams):\n",
    "            if streams[idx]['time_stamps'].shape[0] == 0:\n",
    "                # ignore empty streams\n",
    "                continue\n",
    "            if stream[\"info\"][\"name\"] == [\"markers\"]:\n",
    "                marker = idx\n",
    "            elif stream[\"info\"][\"name\"] == [\"eeg\"]:\n",
    "                eeg = idx\n",
    "            else:\n",
    "                raise Exception(f\"stream info name unknown {stream['info']['name']}\")\n",
    "\n",
    "        if marker == -1 or eeg == -1:\n",
    "            # eeg or marker stream not found\n",
    "            raise Exception('channels not found')    \n",
    "        \n",
    "        for i in range(0, streams[marker][\"time_stamps\"].shape[0], 2):\n",
    "            event = streams[marker][\"time_series\"][i][0]\n",
    "            if event in ['Starting Complex Eye Tracking Dashboard', 'Starting Simple Eye Tracking Dashboard', '']:\n",
    "                continue\n",
    "            start = streams[marker][\"time_stamps\"][i]\n",
    "            stop = streams[marker][\"time_stamps\"][i+1]\n",
    "\n",
    "            data = []\n",
    "            for j, stamp in enumerate(streams[eeg][\"time_stamps\"]):\n",
    "                if start <= stamp and stamp <= stop: \n",
    "                    data.append(streams[eeg][\"time_series\"][j])\n",
    "            data = np.array(data).T[:8]\n",
    "\n",
    "            trial = mne.io.RawArray(data, info, verbose=False)\n",
    "\n",
    "            if event == 'Starting Cognitive Load Tasks: Balls True, Numbers False, Wheel False':\n",
    "                key = 'ball'\n",
    "            elif event == 'Starting Cognitive Load Tasks: Balls True, Numbers True, Wheel False':\n",
    "                key = 'ball+number'\n",
    "            elif event == 'Starting Cognitive Load Tasks: Balls True, Numbers True, Wheel True':\n",
    "                key = 'ball+number+wheel'\n",
    "            else:\n",
    "                print(f\"key {event} not defined!\")\n",
    "\n",
    "            trials[key].append(trial)\n",
    "        \n",
    "    return trials\n",
    "\n",
    "trails = read_trails(current_experiment_list=experiment_list, baseline_list=baseline_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.time_frequency import psd_welch\n",
    "\n",
    "\n",
    "def eeg_power_band(raw: mne.io.RawArray):\n",
    "    \"\"\"EEG relative power band feature extraction.\n",
    "\n",
    "    This function takes an ``mne.io.RawArray`` object and creates EEG features based\n",
    "    on relative power in specific frequency bands that are compatible with\n",
    "    scikit-learn.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : RawArray\n",
    "        The data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array of shape [n_samples, 5]\n",
    "        Transformed data.\n",
    "    \"\"\"\n",
    "\n",
    "    # bands taken from slides\n",
    "    fmin=8\n",
    "    fmax=60\n",
    "    FREQ_BANDS = {\n",
    "        \"alpha\": [8, 13],\n",
    "        \"beta\": [13.5, 30],\n",
    "        \"gamma\": [30.5, 60],\n",
    "    }\n",
    "    # freqs  = (50, 100)\n",
    "    # raw_notch = raw.copy().notch_filter(freqs=freqs, verbose=False, notch_widths=0.5)\n",
    "    psds, freqs = psd_welch(raw, picks=\"eeg\", fmin=fmin, fmax=fmax, verbose=False)\n",
    "\n",
    "    # Normalize the PSDs\n",
    "    # Baseline in time dimension not neccessary (0th PSD dimension)\n",
    "    psds /= np.sum(psds, axis=-1, keepdims=True)\n",
    "\n",
    "    X = []\n",
    "    for fmin, fmax in FREQ_BANDS.values():\n",
    "        psds_band = psds[:, (freqs >= fmin) & (freqs < fmax)].mean(axis=-1)\n",
    "        # TODO: use statistical features (min, max, var)\n",
    "        # use bins (e.g. 2 Hz range)\n",
    "        X.append(psds_band.reshape(len(psds), -1))\n",
    "\n",
    "    return np.concatenate(X, axis=-2).squeeze()  # concatenate all 8 channels * 3 frequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and class arrays\n",
    "\n",
    "def create_ml_data(trails, step=2):\n",
    "    X = []\n",
    "    y = []\n",
    "    for data_class, data_list in trails.items():\n",
    "        for raw in data_list:\n",
    "\n",
    "            # apply notch filter\n",
    "            freqs = (50, 100)\n",
    "            raw_notch = raw.copy().notch_filter(freqs=freqs, verbose=False, notch_widths=0.5)\n",
    "\n",
    "            # slice and create psd\n",
    "            for start in range(0, int(raw.tmax), step):\n",
    "                raw_crop = raw.copy().crop(tmin=start, tmax=start+step)\n",
    "                X.append(eeg_power_band(raw_crop))\n",
    "                y.append(data_class)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X, y = create_ml_data(trails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report , ConfusionMatrixDisplay\n\u001b[1;32m      8\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m))\n\u001b[0;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m pipe\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2448\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2445\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[1;32m   2447\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 2448\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m   2450\u001b[0m )\n\u001b[1;32m   2452\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m   2453\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2126\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2123\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[1;32m   2125\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2126\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2127\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2128\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2130\u001b[0m     )\n\u001b[1;32m   2132\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report , ConfusionMatrixDisplay\n",
    "\n",
    "pipe = make_pipeline(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels = pipe.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=pipe.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename=\"model\"):\n",
    "    dump(model, f'{filename}.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model=pipe, filename=\"model01\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
